{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd1d009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# -------------- EMBEDDING MODEL ----------------\n",
    "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "model_kwargs = {'device':'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,\n",
    "    model_kwargs=model_kwargs, \n",
    "    encode_kwargs=encode_kwargs \n",
    ")\n",
    "# -----------------------------------------------\n",
    "\n",
    "# -------------------- PATHS --------------------\n",
    "current_dir = os.getcwd()\n",
    "db_dir = os.path.join(current_dir, \"db\")\n",
    "idx_name = \"FAISS_metadata\"\n",
    "# -----------------------------------------------\n",
    "\n",
    "def ensure_faiss_db_exists():\n",
    "\n",
    "    index_path = os.path.join(db_dir, f\"{idx_name}.faiss\")\n",
    "    if not os.path.exists(index_path):\n",
    "\n",
    "        dummy_doc = Document(page_content=\"\", metadata={\"source\": \"init\"})\n",
    "        faissdb = FAISS.from_documents([dummy_doc], embeddings)\n",
    "\n",
    "        faissdb.save_local(folder_path=db_dir, index_name=idx_name)\n",
    "        \n",
    "def text_file_extract(file_name):\n",
    "    \n",
    "    ensure_faiss_db_exists()\n",
    "\n",
    "    file_path = os.path.join(current_dir, \"uploads\", file_name)\n",
    "\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    data = loader.load()\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist. Please check the path.\")\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata = {'source': file_name}\n",
    "\n",
    "    faissdb = FAISS.load_local(\n",
    "        folder_path=db_dir,\n",
    "        embeddings=embeddings,\n",
    "        index_name=idx_name,\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "\n",
    "    faissdb.add_documents(chunks)\n",
    "\n",
    "    faissdb.save_local(folder_path=db_dir, index_name=idx_name)\n",
    "\n",
    "def pdf_file_extract(file_name):\n",
    "\n",
    "    ensure_faiss_db_exists()\n",
    "\n",
    "    file_path = os.path.join(current_dir, \"uploads\", file_name)\n",
    "\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    data = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=10,\n",
    "        length_function=len,\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata = {'source': file_name}\n",
    "\n",
    "    faissdb = FAISS.load_local(\n",
    "        folder_path=db_dir,\n",
    "        embeddings=embeddings,\n",
    "        index_name=idx_name,\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "\n",
    "    faissdb.add_documents(chunks)\n",
    "\n",
    "    faissdb.save_local(folder_path=db_dir, index_name=idx_name)\n",
    "\n",
    "def retrieve_relevant_data(query):\n",
    "\n",
    "    if not os.path.exists(os.path.join(db_dir, f\"{idx_name}.faiss\")):\n",
    "        return \"\"\"No Documents Are Added.\"\"\"\n",
    "\n",
    "    faissdb = FAISS.load_local(\n",
    "        folder_path=db_dir, \n",
    "        embeddings=embeddings, \n",
    "        index_name=idx_name, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "    sim_retriever = faissdb.as_retriever(\n",
    "        search_type='similarity',\n",
    "        search_kwargs={'k':5},\n",
    "    )\n",
    "\n",
    "    relevant_doc1 = sim_retriever.invoke(query)\n",
    "\n",
    "    result = \"\"\n",
    "\n",
    "    for doc in relevant_doc1:\n",
    "        result += f'\\nRelevant Doc: \\n {doc.page_content}'\n",
    "        result += f'\\nSource: {doc.metadata}'\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4794f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"romeo_and_juliet.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14897cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"NVResume.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69e0aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_name.endswith('.txt'):\n",
    "    text_file_extract(file_name)\n",
    "elif file_name.endswith('pdf'):\n",
    "    pdf_file_extract(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0657887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nithin Vikas AV is an individual whose resume details are provided in the context. He is currently pursuing an M.Sc. in Cyber Security (Integrated) at PSG College of Technology and is also in Grade 12 at Nava Bharath National School. He possesses technical skills in languages like C/C++, Java, Python, and SQL, along with knowledge in Data Structures and Algorithms, Operating Systems, Computer Networks, DBMS, and OOPs. He has also worked on projects such as \"HoneyPot-Lite\" (cybersecurity-related) and a \"2D Adventure Game\" (software development).\n",
      "\n",
      "Based on his M.Sc. in Cyber Security, his \"HoneyPot-Lite\" project, and his technical skills in Python, Computer Networks, and Operating Systems, Nithin Vikas AV appears to be well-suited for roles in **cybersecurity**, **network security**, or **junior software development** positions, especially those involving Python or Java.\n",
      "\n",
      "Source: NVResume.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash', google_api_key=api_key)\n",
    "\n",
    "query = \"Who is Nithin Vikas and which role he suits for in job?\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "        ** Use the Given Context to answer the question. Also provide the Source name you picked from **\n",
    "        If the Answer is not in the context then notify the user about no information regarding the question in the context.\n",
    "        If the Provided Question is not relevant to the context then answer through the data which you trained on.\n",
    "        \n",
    "        {retrieve_relevant_data(query)}\n",
    "        \n",
    "        You are a Helpful AI Assitant who patiently answers every user's query.\n",
    "\n",
    "        User Query: {query}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c99ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
